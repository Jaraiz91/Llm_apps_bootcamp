{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "openai_api_key = os.environ[\"OPENAI_API_KEY\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load private document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import (\n",
    "    VectorStoreIndex,\n",
    "    SimpleDirectoryReader,\n",
    "    StorageContext,\n",
    "    load_index_from_storage\n",
    ")\n",
    "\n",
    "documents = SimpleDirectoryReader('data').load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc ID: d24d10c5-5120-441a-b88e-48719a0b0362\n",
      "Text: Aplicaciones LLM  LlamaIndex  © 2023 Julio Colomer, Aceleradora\n",
      "AI\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(documents[0])\n",
    "len(documents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jarai\\anaconda3\\envs\\llm\\lib\\site-packages\\pydantic\\_internal\\_fields.py:132: UserWarning: Field \"model_name\" in HuggingFaceInferenceAPIEmbeddings has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "index = VectorStoreIndex.from_documents(documents=documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ask questions to private document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response(response='The document discusses optimizing advanced retrieval strategies, evaluation, and building performant RAG applications for production. It also covers various use cases such as QA, chatbot, agent, structured data extraction, and multimodal applications. The content is authored by Julio Colomer from Aceleradora AI and is focused on enhancing retrieval strategies, application performance, and exploring different use cases like QA and chatbots.', source_nodes=[NodeWithScore(node=TextNode(id_='65b85065-8ed3-4463-80e0-56ed70eefd40', embedding=None, metadata={'page_label': '6', 'file_name': '116BESP-LLAMAINDEX.pdf', 'file_path': 'c:\\\\Users\\\\jarai\\\\OneDrive\\\\Escritorio\\\\git\\\\Llm_apps_bootcamp\\\\LlamaIndex\\\\data\\\\116BESP-LLAMAINDEX.pdf', 'file_type': 'application/pdf', 'file_size': 45439, 'creation_date': '2024-10-24', 'last_modified_date': '2024-10-24'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='97372006-1dd5-4b4d-911a-eed907643a25', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '6', 'file_name': '116BESP-LLAMAINDEX.pdf', 'file_path': 'c:\\\\Users\\\\jarai\\\\OneDrive\\\\Escritorio\\\\git\\\\Llm_apps_bootcamp\\\\LlamaIndex\\\\data\\\\116BESP-LLAMAINDEX.pdf', 'file_type': 'application/pdf', 'file_size': 45439, 'creation_date': '2024-10-24', 'last_modified_date': '2024-10-24'}, hash='38fee3afb3e4dcb5d068073744da411a08e3b7e37db21b99c6bf13242095ded7')}, text='Optimizing \\n●Advanced Retrieval Strategies \\n●Evaluation \\n●Building performant RAG applications for production \\n© 2023 Julio Colomer, Aceleradora AI', mimetype='text/plain', start_char_idx=0, end_char_idx=147, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.7687216221339361), NodeWithScore(node=TextNode(id_='d84fdf43-5132-426d-9547-74f60a6fd808', embedding=None, metadata={'page_label': '5', 'file_name': '116BESP-LLAMAINDEX.pdf', 'file_path': 'c:\\\\Users\\\\jarai\\\\OneDrive\\\\Escritorio\\\\git\\\\Llm_apps_bootcamp\\\\LlamaIndex\\\\data\\\\116BESP-LLAMAINDEX.pdf', 'file_type': 'application/pdf', 'file_size': 45439, 'creation_date': '2024-10-24', 'last_modified_date': '2024-10-24'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='d2b77f08-0f83-425a-bea2-b5ee73debd32', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'page_label': '5', 'file_name': '116BESP-LLAMAINDEX.pdf', 'file_path': 'c:\\\\Users\\\\jarai\\\\OneDrive\\\\Escritorio\\\\git\\\\Llm_apps_bootcamp\\\\LlamaIndex\\\\data\\\\116BESP-LLAMAINDEX.pdf', 'file_type': 'application/pdf', 'file_size': 45439, 'creation_date': '2024-10-24', 'last_modified_date': '2024-10-24'}, hash='5bdaddaee8be98451d6db4fefc2a939b0accf0c8783c713537a5d0d7e935c91a')}, text='Use cases \\n●QA\\n●Chatbot \\n●Agent \\n●Structured Data Extraction \\n●Multimodal \\n© 2023 Julio Colomer, Aceleradora AI', mimetype='text/plain', start_char_idx=0, end_char_idx=111, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.7681225350138313)], metadata={'65b85065-8ed3-4463-80e0-56ed70eefd40': {'page_label': '6', 'file_name': '116BESP-LLAMAINDEX.pdf', 'file_path': 'c:\\\\Users\\\\jarai\\\\OneDrive\\\\Escritorio\\\\git\\\\Llm_apps_bootcamp\\\\LlamaIndex\\\\data\\\\116BESP-LLAMAINDEX.pdf', 'file_type': 'application/pdf', 'file_size': 45439, 'creation_date': '2024-10-24', 'last_modified_date': '2024-10-24'}, 'd84fdf43-5132-426d-9547-74f60a6fd808': {'page_label': '5', 'file_name': '116BESP-LLAMAINDEX.pdf', 'file_path': 'c:\\\\Users\\\\jarai\\\\OneDrive\\\\Escritorio\\\\git\\\\Llm_apps_bootcamp\\\\LlamaIndex\\\\data\\\\116BESP-LLAMAINDEX.pdf', 'file_type': 'application/pdf', 'file_size': 45439, 'creation_date': '2024-10-24', 'last_modified_date': '2024-10-24'}})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query('Summarize the document in 100 words')\n",
    "response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The document discusses optimizing advanced retrieval strategies, evaluation, and building performant RAG applications for production. It also covers various use cases such as QA, chatbot, agent, structured data extraction, and multimodal applications. The content is authored by Julio Colomer from Aceleradora AI and is focused on enhancing retrieval strategies, application performance, and exploring different use cases like QA and chatbots.\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "\n",
    "\n",
    "#check if storage already exists\n",
    "if not os.path.exists('./storage'):\n",
    "    #load the documents and create the index\n",
    "    documents = SimpleDirectoryReader('data').load_data()\n",
    "    index = VectorStoreIndex.from_documents(documents=documents)\n",
    "    #store it for later\n",
    "    index.storage_context.persist()\n",
    "else:\n",
    "    #load the existing index\n",
    "    storage_context = StorageContext.from_defaults(persist_dir='./storage')\n",
    "    index = load_index_from_storage(storage_context=storage_context)\n",
    "\n",
    "# either way we can now query the index\n",
    "quey_engine = index.as_query_engine()\n",
    "query_engine = query_engine.query('According to the author, what is good?')\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customization options\n",
    "* parse into smaller chunks\n",
    "* use a different vector store\n",
    "* retrieve more context when I query\n",
    "* use a different LLM\n",
    "* use a different response mode\n",
    "* stream the response back"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use cases\n",
    "* QA\n",
    "* Chatbot\n",
    "* Agent\n",
    "* Structured Data Extraction\n",
    "* Multimodal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimizing\n",
    "* Advanced Retrieval Strategies\n",
    "* Evaluation\n",
    "* Building performant RAG applications for production"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other\n",
    "* LlamaPacks and Create-llama = LangChain templates\n",
    "* Very recent, still in beta\n",
    "* Very interesting: create-llama allows you to create a Vercel app!\n",
    "* Very interesting: open-source end-to-end project (SEC Insights)\n",
    "    * llamaindex + react/nextjs (vercel) + fastAPI + render + AWS\n",
    "    * environment setup: localStack + docker\n",
    "    * monitoring: sentry\n",
    "    * load testing: loader.io\n",
    "    * [web](https://www.secinsights.ai/)\n",
    "    * [code](https://github.com/run-llama/sec-insights)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
